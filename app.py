import streamlit as st
import numpy as np
import pandas as pd
import joblib
from partner_matching import match_partners

# ---------------------------------------------
# 1) í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ---------------------------------------------
st.set_page_config(page_title="AI StudyMate - í•™ìŠµ ì„±í–¥ ë¶„ì„", layout="wide")
st.title("ğŸ§  AI StudyMate - í•™ìŠµ ì„±í–¥ ì§„ë‹¨")
st.write("30ë¬¸í•­ ì„¤ë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµ ì„±í–¥ì„ ë¶„ì„í•˜ê³ , ë§ì¶¤í˜• í•˜ë¸Œë£¨íƒ€ íŒŒíŠ¸ë„ˆ ìœ í˜•ê³¼ í•™ìŠµë²•ì„ ì¶”ì²œí•©ë‹ˆë‹¤.")
st.divider()

# ---------------------------------------------
# 2) ì„¤ë¬¸ ë¬¸í•­ ì •ì˜ (Q1~Q30)
# ---------------------------------------------
questions = [
    "ë‚˜ëŠ” ë¬¸ì œë¥¼ í’€ê¸° ì „ì— ê³„íšì„ ì„¸ìš°ëŠ” í¸ì´ë‹¤.",
    "ìƒˆë¡œìš´ ë‚´ìš©ì„ ë°°ìš°ë©´ ìŠ¤ìŠ¤ë¡œ ì •ë¦¬í•´ë³´ëŠ” í¸ì´ë‹¤.",
    "ì–´ë ¤ìš´ ë¬¸ì œê°€ ë‚˜ì˜¤ë©´ ë°”ë¡œ ì§ˆë¬¸í•˜ê¸°ë³´ë‹¤ëŠ” ë¨¼ì € ìŠ¤ìŠ¤ë¡œ í•´ê²°í•˜ë ¤ í•œë‹¤.",
    "ì¹œêµ¬ì™€ í•¨ê»˜ ê³µë¶€í•˜ë©´ ë” ì˜ ì´í•´ëœë‹¤.",
    "ë‹¤ë¥¸ ì‚¬ëŒì˜ ìƒê°ì„ ë“£ê³  ë¹„êµí•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•œë‹¤.",
    "í† ë¡  í™œë™ì´ ë‚˜ì—ê²Œ ë„ì›€ì´ ëœë‹¤.",
    "ë‚˜ëŠ” í˜¼ì ê³µë¶€í•˜ëŠ” ê²ƒì´ ë” í¸í•˜ë‹¤.",
    "í•™ìŠµ ëª©í‘œë¥¼ ìŠ¤ìŠ¤ë¡œ ì„¤ì •í•˜ëŠ” í¸ì´ë‹¤.",
    "í‹€ë¦° ë¬¸ì œë¥¼ ë‹¤ì‹œ ë¶„ì„í•˜ëŠ” ë° ì‹œê°„ì„ íˆ¬ìí•œë‹¤.",
    "ë‚´ê°€ ëª¨ë¥´ëŠ” ê²ƒì„ ì†”ì§í•˜ê²Œ ë§í•˜ëŠ” í¸ì´ë‹¤.",
    "ì¹œêµ¬ê°€ ì§ˆë¬¸í•˜ë©´ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ëŠ” í¸ì´ë‹¤.",
    "íŒ€ í™œë™ì—ì„œ ì˜ê²¬ ì¡°ìœ¨ì„ ì˜í•˜ëŠ” í¸ì´ë‹¤.",
    "ë¬¸ì œë¥¼ ë‹¤ì–‘í•˜ê²Œ ë°”ê¿”ë³´ë©° íƒêµ¬í•˜ëŠ” í¸ì´ë‹¤.",
    "ìƒˆë¡œìš´ ë°©ì‹ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•œë‹¤.",
    "ì›ë¦¬ë¥¼ ì´í•´í•´ì•¼ ì•ˆì‹¬ëœë‹¤.",
    "ë‚˜ì˜ í•™ìŠµ ìŠµê´€ì„ ìŠ¤ìŠ¤ë¡œ ì ê²€í•œë‹¤.",
    "í•™ìŠµ ìŠ¤ì¼€ì¤„ì„ ì§€í‚¤ë ¤ê³  ë…¸ë ¥í•œë‹¤.",
    "ëª¨ë¥´ëŠ” ê²ƒì´ ìˆìœ¼ë©´ ë°”ë¡œ ê²€ìƒ‰í•˜ê±°ë‚˜ ì°¾ëŠ”ë‹¤.",
    "ì¹œêµ¬ì™€ ì•„ì´ë””ì–´ë¥¼ ì£¼ê³ ë°›ëŠ” ê²ƒì„ ì¢‹ì•„í•œë‹¤.",
    "ì„œë¡œì˜ í’€ì´ë¥¼ ë¹„êµí•´ë³´ëŠ” í™œë™ì„ ì¢‹ì•„í•œë‹¤.",
    "ì§ˆë¬¸ì„ í™œë°œí•˜ê²Œ í•˜ëŠ” í¸ì´ë‹¤.",
    "ë¬¸ì œì˜ ë‹¤ì–‘í•œ ê²½ìš°ë¥¼ ì‹¤í—˜í•˜ëŠ” í¸ì´ë‹¤.",
    "ë³µì¡í•œ ë¬¸ì œë¥¼ ë‹¨ê³„ì ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ìƒê°í•œë‹¤.",
    "ë‚´ê°€ ì´í•´í•œ ê²ƒì„ ì •ë¦¬í•´ì„œ ë§í•  ìˆ˜ ìˆë‹¤.",
    "ìˆ˜ì—… ì¤‘ ë°œí‘œë‚˜ ì„¤ëª…ì„ ì˜í•˜ëŠ” í¸ì´ë‹¤.",
    "ì˜¤ë‹µì„ ë¶„ì„í•˜ì—¬ ê³µë¶€ ë°©í–¥ì„ ì¡°ì •í•œë‹¤.",
    "ëª¨ë‘  í™œë™ì—ì„œ ì£¼ë„ì ìœ¼ë¡œ ì°¸ì—¬í•œë‹¤.",
    "ì–´ë ¤ìš´ ë‚´ìš©ì„ ë°˜ë³µí•´ì„œ íƒêµ¬í•´ë³¸ë‹¤.",
    "ë°°ìš´ ë‚´ìš©ì„ ë‹¤ë¥¸ ì‚¬ëŒì—ê²Œ ì„¤ëª…í•´ë³¸ë‹¤.",
    "ë‹¤ë¥¸ ì‚¬ëŒê³¼ í•™ìŠµí•  ë•Œ ë™ê¸°ë¶€ì—¬ê°€ ëœë‹¤."
]

CHOICES = ["â‘  ì „í˜€ ì•„ë‹ˆë‹¤", "â‘¡ ì•„ë‹ˆë‹¤", "â‘¢ ë³´í†µì´ë‹¤", "â‘£ ê·¸ë ‡ë‹¤", "â‘¤ ë§¤ìš° ê·¸ë ‡ë‹¤"]

st.subheader("ğŸ“˜ í•™ìŠµ ì„±í–¥ ì„¤ë¬¸ (30ë¬¸í•­)")
responses = {}
for i, question in enumerate(questions, start=1):
    choice = st.radio(
        f"**Q{i}. {question}**",
        CHOICES,
        key=f"q_{i}",
        horizontal=True
    )
    responses[f"Q{i}"] = CHOICES.index(choice) + 1
    st.markdown("---")

# ---------------------------------------------
# 3) í•™ìŠµ ì„±í–¥ ë¶„ì„
# ---------------------------------------------
if st.button("ğŸ§ª í•™ìŠµ ì„±í–¥ ë¶„ì„ ì‹œì‘"):
    responses_list = [CHOICES.index(st.session_state[f"q_{i}"]) + 1 for i in range(1,31)]

    responses_array = np.array(responses_list)
    Analytical_idx = [0, 2, 8, 14, 22]
    Collaborative_idx = [3, 4, 10, 11, 18, 19, 25]
    SelfDirected_idx = [1, 6, 7, 15, 16, 26]
    Questioning_idx = [5, 12, 13, 20, 21, 27, 28]

    Analytical = responses_array[Analytical_idx].mean()
    Collaborative = responses_array[Collaborative_idx].mean()
    SelfDirected = responses_array[SelfDirected_idx].mean()
    Questioning = responses_array[Questioning_idx].mean()

    profile_vector = np.array([Analytical, Collaborative, SelfDirected, Questioning]).reshape(1,-1)

    # ---------------------------------------------
    # 4) ìŠ¤ì¼€ì¼ëŸ¬ + KMeans ë¶ˆëŸ¬ì˜¤ê¸°
    # ---------------------------------------------
    try:
        scaler = joblib.load("scaler.pkl")
        kmeans = joblib.load("kmeans_model.pkl")
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        st.stop()

    # feature ì´ë¦„ ë§ì¶”ê¸°
    df_profile = pd.DataFrame({
        'competency_label_1':[Analytical],
        'competency_label_2':[SelfDirected],
        'competency_label_3':[Collaborative],
        'competency_label_4':[Questioning]
    })
    X_scaled = scaler.transform(df_profile)
    cluster = int(kmeans.predict(X_scaled)[0])

    # ---------------------------------------------
    # 5) Strength Profile & íŒŒíŠ¸ë„ˆ ì¶”ì²œ ì •ë³´
    # ---------------------------------------------
    cluster_name_map = {
        0: "ë³‘ì•„ë¦¬ íƒí—˜ê°€ ğŸ£",
        1: "ë…¼ë¦¬ì™• ğŸ¤“",
        2: "ì¹œêµ¬ì™• ğŸ¦„",
        3: "ë¬¸ì œ í•´ê²° ë§ˆìŠ¤í„° ğŸ•µï¸â€â™‚ï¸"
    }
    partner_recommendation_map = {
        0: "ë¬¸ì œ í•´ê²° ë§ˆìŠ¤í„° ğŸ•µï¸â€â™‚ï¸ ì¹œêµ¬ì™€ í•¨ê»˜í•˜ë©´ ê¸°ë³¸ê¸° í˜•ì„±ì´ ë¹ ë¦…ë‹ˆë‹¤.",
        1: "ì¹œêµ¬ì™• ğŸ¦„ ì¹œêµ¬ì™€ í•¨ê»˜í•˜ë©´ í˜‘ë ¥ í•™ìŠµê³¼ ì´í•´ê°€ í–¥ìƒë©ë‹ˆë‹¤.",
        2: "ë…¼ë¦¬ì™• ğŸ¤“ ì¹œêµ¬ì™€ í•¨ê»˜í•˜ë©´ ì‚¬ê³ ë ¥ê³¼ ê³„íšë ¥ì´ ê°•í™”ë©ë‹ˆë‹¤.",
        3: "ë³‘ì•„ë¦¬ íƒí—˜ê°€ ğŸ£ ì¹œêµ¬ì™€ í•¨ê»˜ í™œë™í•˜ë©´ ê°œë… ì´í•´ì™€ í•™ìŠµ ë£¨í‹´ í˜•ì„±ì— ë„ì›€ë©ë‹ˆë‹¤."
    }

    # Strength Profile ì˜ˆì‹œ
    strength_profile_map = {
        0: {"í•™ìŠµ ìŠ¤íƒ€ì¼ ë¶„ì„":["ê¸°ì´ˆ ê°œë… ì´í•´ì™€ ë°˜ë³µ í•™ìŠµì„ ì˜í•¨"],"ì´ë ‡ê²Œ ê³µë¶€í•˜ë©´ ì¢‹ì•„ìš”":["ë…¸íŠ¸ ì •ë¦¬"],"ì¹œêµ¬ì™€ í•¨ê»˜ ê³µë¶€í•  ë•Œ ì—­í• ":["íƒí—˜ê°€ ì—­í• "]},
        1: {"í•™ìŠµ ìŠ¤íƒ€ì¼ ë¶„ì„":["ë…¼ë¦¬ì  ë¶„ì„ê³¼ ë‹¨ê³„ì  ë¬¸ì œ í•´ê²°"],"ì´ë ‡ê²Œ ê³µë¶€í•˜ë©´ ì¢‹ì•„ìš”":["ê³„íší‘œ ì‘ì„± í›„ í’€ì´"],"ì¹œêµ¬ì™€ í•¨ê»˜ ê³µë¶€í•  ë•Œ ì—­í• ":["ë¶„ì„ê°€ ì—­í• "]},
        2: {"í•™ìŠµ ìŠ¤íƒ€ì¼ ë¶„ì„":["ì¹œêµ¬ì™€ í•¨ê»˜ í† ë¡  ë° ì´í•´"],"ì´ë ‡ê²Œ ê³µë¶€í•˜ë©´ ì¢‹ì•„ìš”":["ê·¸ë£¹ í† ë¡ "],"ì¹œêµ¬ì™€ í•¨ê»˜ ê³µë¶€í•  ë•Œ ì—­í• ":["ì„¤ëª…ê°€ ì—­í• "]},
        3: {"í•™ìŠµ ìŠ¤íƒ€ì¼ ë¶„ì„":["ë¬¸ì œ íƒêµ¬ì™€ ì‘ìš© í™œë™"],"ì´ë ‡ê²Œ ê³µë¶€í•˜ë©´ ì¢‹ì•„ìš”":["ë¬¸ì œ ë³€í˜• í’€ì´"],"ì¹œêµ¬ì™€ í•¨ê»˜ ê³µë¶€í•  ë•Œ ì—­í• ":["ë¬¸ì œ í•´ê²°ì‚¬ ì—­í• "]},
    }

    # session_state ì €ì¥
    st.session_state['Analytical'] = Analytical
    st.session_state['Collaborative'] = Collaborative
    st.session_state['SelfDirected'] = SelfDirected
    st.session_state['Questioning'] = Questioning
    st.session_state['cluster'] = cluster
    st.session_state['cluster_name'] = cluster_name_map[cluster]
    st.session_state['partner_recommendation'] = partner_recommendation_map[cluster]
    st.session_state['strength_profile'] = strength_profile_map[cluster]

    # í•™ìƒ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° + match_partners
    try:
        df_students_raw = pd.read_csv("real_students.csv")
        df_students_processed = match_partners(df_students_raw)
        st.session_state['students_processed'] = df_students_processed
    except Exception as e:
        st.warning(f"í•™ìƒ ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        st.session_state['students_processed'] = pd.DataFrame(columns=['ID','grade','Cluster'])

# ---------------------------------------------
# 6) ê²°ê³¼ ì¶œë ¥ + í•™ìŠµ ë©”ì´íŠ¸ ì¶”ì²œ í†µí•©
# ---------------------------------------------
if 'cluster' in st.session_state:
    Analytical = st.session_state['Analytical']
    Collaborative = st.session_state['Collaborative']
    SelfDirected = st.session_state['SelfDirected']
    Questioning = st.session_state['Questioning']
    cluster = st.session_state['cluster']

    # ì—­ëŸ‰ ì¹´ë“œ
    st.subheader("ğŸ“Œ ë¶„ì„ ê²°ê³¼ ìš”ì•½")
    st.metric("ì˜ˆì¸¡ëœ í•™ìŠµì ìœ í˜•", st.session_state['cluster_name'])
    col1, col2 = st.columns(2)
    with col1:
        st.write("### ğŸ¯ ë‚˜ì˜ ì—­ëŸ‰ ì ìˆ˜")
        st.write(f"- Analytical: {Analytical:.2f}/5.0")
        st.write(f"- Collaborative: {Collaborative:.2f}/5.0")
        st.write(f"- SelfDirected: {SelfDirected:.2f}/5.0")
        st.write(f"- Questioning: {Questioning:.2f}/5.0")
    with col2:
        st.write("### ğŸ¤ ì¶”ì²œ í•˜ë¸Œë£¨íƒ€ íŒŒíŠ¸ë„ˆ ìœ í˜•")
        st.info(st.session_state['partner_recommendation'])

    # Strength Profile ì¹´ë“œ
    st.divider()
    st.subheader("ğŸ“‡ ë‚˜ì˜ Strength Profile ì¹´ë“œ")
    for title, points in st.session_state['strength_profile'].items():
        points_html = "".join([f"<p style='margin:5px 0;'>- {p}</p>" for p in points])
        st.markdown(
            f"""
            <div style="background-color:#f0f4f8;padding:18px;border-radius:12px;margin-bottom:12px;box-shadow:2px 2px 8px rgba(0,0,0,0.1);">
                <h4 style="color:#1f4e79;">{title}</h4>
                {points_html}
            </div>
            """,
            unsafe_allow_html=True
        )

    # í•™ìŠµ ë©”ì´íŠ¸ ì¶”ì²œ
    complement_map = {0:3,1:2,2:1,3:0}
    df_students = st.session_state.get('students_processed', pd.DataFrame(columns=['ID','grade','Cluster']))

    st.divider()
    st.subheader("ğŸ§‘â€ğŸ¤â€ğŸ§‘ í•™ìŠµ ë©”ì´íŠ¸ ì¶”ì²œ")
    cluster_user = int(cluster)
    target_cluster = complement_map[cluster_user]

    recommended_complement = df_students[df_students['Cluster']==target_cluster][['ID','grade']].head(3)
    st.subheader("ğŸ¯ ì¶”ì²œ í•™ìŠµ ë©”ì´íŠ¸ (ë³´ì™„í˜•)")
    st.dataframe(recommended_complement.reset_index(drop=True))

    recommended_similar = df_students[df_students['Cluster']==cluster_user][['ID','grade']].head(3)
    st.subheader("ğŸ¯ ì¶”ì²œ í•™ìŠµ ë©”ì´íŠ¸ (ìœ ì‚¬í˜•)")
    st.dataframe(recommended_similar.reset_index(drop=True))
